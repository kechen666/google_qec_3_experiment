{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在噪声模型下，基于超图解码的MLD方法与基于图的Matching方法之间的差别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取一些不同d和r的stim噪声电路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "\n",
    "rounds = [1,3,5,7,9,11,13,15]\n",
    "distances = [3,5]\n",
    "\n",
    "def read_circuit(d : int, r : int)->stim.Circuit:\n",
    "    \"\"\"根据相对路径, 读取stim格式的噪声电路.\n",
    "\n",
    "    Args:\n",
    "        d (int): 码矩\n",
    "        r (int): 轮次\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    if d==3:\n",
    "        if r<10:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./surface_code_bZ_d3_r0{r}_center_3_5/circuit_noisy.stim\")\n",
    "        else:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./surface_code_bZ_d3_r{r}_center_3_5/circuit_noisy.stim\")\n",
    "    elif d==5:\n",
    "        if r<10:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./surface_code_bZ_d5_r0{r}_center_5_5/circuit_noisy.stim\")\n",
    "        else:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./surface_code_bZ_d5_r{r}_center_5_5/circuit_noisy.stim\")    \n",
    "    return circuit_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取所有的噪声电路和对应的错误检测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_circuits = [read_circuit(d,r) for d in distances for r in rounds]\n",
    "detector_error_models = [c.detector_error_model() for c in noisy_circuits]\n",
    "decomposed_detector_error_models = [c.detector_error_model(decompose_errors=True) for c in noisy_circuits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_error_models[0].num_observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们创建不同的解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# 设置 logging 配置\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "from typing import List, Union, Optional, Tuple, Set, Dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class MaxLikelihoodDecoder:\n",
    "    def __init__(self, detector_error_model: stim.DetectorErrorModel, detector_number: Union[int, None] = None, logical_number: Union[int, None] = 1):\n",
    "        \"\"\"构建最大似然解码器的初始化\n",
    "\n",
    "        Args:\n",
    "            detector_error_model (stim.DetectorErrorModel): 检测错误模型\n",
    "            detector_number (Union[int, None], optional): 检测器的个数. Defaults to None.\n",
    "            logical_number (Union[int, None], optional): 逻辑比特的个数. Defaults to 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.detector_error_model = detector_error_model\n",
    "        if detector_number is None:\n",
    "            self.detector_number = detector_error_model.num_detectors\n",
    "        else:\n",
    "            self.detector_number = detector_number\n",
    "        \n",
    "        if logical_number is None:\n",
    "            self.logical_number = detector_error_model.num_observables\n",
    "        else:\n",
    "            self.logical_number = logical_number\n",
    "        \n",
    "        self.detector_error_model_dict = self.get_detector_error_model_dict(detector_error_model, self.detector_number)\n",
    "        \n",
    "    def decode(self, measurement_outcomes: List[str]) -> List[int]:\n",
    "        \"\"\"解码操作\n",
    "\n",
    "        Args:\n",
    "            measurement_outcomes (List[str]): 用于解码的syndrome, 对应测量比特的结果, 格式为['01101010', '10010101'].\n",
    "\n",
    "        Returns:\n",
    "            List[int]: 是否进行逻辑纠错, 其中1表示进行纠错, 0表示不进行纠错。\n",
    "        \"\"\"\n",
    "        error_correction_operation = []\n",
    "        for syndrome in measurement_outcomes:\n",
    "            \n",
    "            syndrome_probability_distribution = self.compute_syndrome_probability_distribution(syndrome)\n",
    "            max_probability_detector_observable =  max(syndrome_probability_distribution, key=syndrome_probability_distribution.get)\n",
    "            probability = syndrome_probability_distribution[max_probability_detector_observable] / sum(syndrome_probability_distribution.values())\n",
    "            \n",
    "            observable = max_probability_detector_observable[self.detector_number:]\n",
    "            \n",
    "            if len(observable) == 1:\n",
    "                # 只有一个量子比特被翻转\n",
    "                if observable == \"0\":\n",
    "                    logging.info(f\"no error, no use logical flip, the correct probability is {probability}\")\n",
    "                    error_correction_operation.append(0)\n",
    "                else:\n",
    "                    logging.info(f\"error, use logical flip, the correct probability is {probability}\")\n",
    "                    error_correction_operation.append(0)\n",
    "            else:\n",
    "                raise(\"Now, only for one logical qubit\")\n",
    "        return error_correction_operation\n",
    "\n",
    "    def get_detector_logical_observable_val(self, targets_copy: List[stim.DemTarget], detector_number: int) -> List[int]:\n",
    "        \"\"\"从一个error事件中, 获取它所翻转的detector和logical_observable的index\n",
    "\n",
    "        Args:\n",
    "            targets_copy (List[stim.DemTarget]): 错误事件中的detector或logical_observable对象\n",
    "            detector_number (int): detector的个数\n",
    "            \n",
    "        Returns:\n",
    "            List[int]: 翻转的detector和logical_observable的index列表\n",
    "        \"\"\"\n",
    "        target_val = []\n",
    "        for target in targets_copy:\n",
    "            if target.is_relative_detector_id():\n",
    "                target_val.append(target.val)\n",
    "            elif target.is_logical_observable_id():\n",
    "                target_val.append(target.val + detector_number)\n",
    "        return target_val\n",
    "    \n",
    "    def get_detector_error_model_dict(self, detector_error_model: stim.DetectorErrorModel, detector_number:int) -> Dict[Tuple[int], float]:\n",
    "        \"\"\"生成一个detector和logical_observable的翻转index的作为key, 出现概率作为value的字典\n",
    "\n",
    "        Args:\n",
    "            detector_error_model (stim.DetectorErrorModel): 错误检测模型\n",
    "            detector_number (int): detector的个数\n",
    "\n",
    "        Returns:\n",
    "            Dict[Tuple[int], float]: detector和logical_observable的翻转index的作为key, 出现概率作为value的字典. \n",
    "            eg. {(0,2): 0.000005,.....,(7,):0.00005}\n",
    "        \"\"\"\n",
    "        detector_error_model_dict = {}\n",
    "\n",
    "        for error in detector_error_model:\n",
    "            if error.type == \"error\":\n",
    "                probability = error.args_copy()[0]\n",
    "                targets_copy = error.targets_copy()\n",
    "                fliped_detector_observable_index = self.get_detector_logical_observable_val(targets_copy, detector_number)\n",
    "                detector_error_model_dict[tuple(fliped_detector_observable_index)] = probability\n",
    "        return detector_error_model_dict \n",
    "                    \n",
    "    def flip_detector_observable_index_by_flip_index(self, detector_observable: str, flip_detector_observable_index: Tuple[int]) -> str:\n",
    "        \"\"\"根据翻转的检测器或逻辑观测值的index, 翻转检测器或逻辑观测值\n",
    "\n",
    "        Args:\n",
    "            detector_observable (str): 检测器或逻辑观测值\n",
    "            flip_detector_observable_index (Tuple[int]): 翻转的检测器或逻辑观测值的index\n",
    "\n",
    "        Returns:\n",
    "            str: 翻转后的检测器或逻辑观测值\n",
    "        \"\"\"\n",
    "        fliped_detector_observable = detector_observable\n",
    "    \n",
    "        for i in flip_detector_observable_index:\n",
    "            if detector_observable[i] == '0':\n",
    "                fliped_detector_observable = fliped_detector_observable[:i]+'1'+fliped_detector_observable[i+1:]\n",
    "            else:\n",
    "                fliped_detector_observable = fliped_detector_observable[:i]+'0'+fliped_detector_observable[i+1:]\n",
    "        \n",
    "        return fliped_detector_observable\n",
    "    \n",
    "    def compute_syndrome_probability_distribution(self, syndrome: str) -> Dict[str, float]:\n",
    "        \"\"\"当前syndrome(测量比特的测量值)的概率分布，具体的计算方法如下：\n",
    "        1. 初始化一个字典, key为全为0表示detector+observable的字符串, value为概率, 初始值为1.\n",
    "        2. 遍历syndrome中的每一个detector_i, 作用与detector_i相关的所有错误事件, 更新字典中的概率分布.（每个错误事件作用一次, 我们根据最前面的detector来取相关错误事件, 这样每个错误事件就只取一次）\n",
    "        3. 在作用完与当前detector_i的所有错误事件后, 根据detector_i的测量值, 删除一些无关的分布。例如detector_i测量值为0, 那么所有与detector_i为1的分布将不需要考虑。\n",
    "\n",
    "        Args:\n",
    "            syndrome (str): 测量比特的测量值\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: 当前syndrome(测量比特的测量值)的概率分布, 规模与逻辑比特数量有关, 对于逻辑比特为n, 一般为2^n。\n",
    "        \"\"\"\n",
    "        if isinstance(syndrome, str):\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\"syndrome must be a string\")\n",
    "        \n",
    "        error_probability_distribution = {}\n",
    "        initial_detector_observable = '0'*(self.detector_number + self.logical_number)\n",
    "        error_probability_distribution[initial_detector_observable] = 1\n",
    "        \n",
    "        for detector_i in range(self.detector_number):\n",
    "            syndrome_detector_i = syndrome[detector_i]\n",
    "            # 找到第i个检测器对应的所有错误事件，这里采用的是k[0]，因为默认detector_error_model_dict是存在顺序的，k[0]一般指的是最小的检测器编号\n",
    "            related_detector_error_model_dict = {k:v for k,v in self.detector_error_model_dict.items() if detector_i == k[0]}\n",
    "            for flip_detector_observable_index, flip_probability in related_detector_error_model_dict.items():\n",
    "                # 执行与第i个检测器相关的所有错误事件。\n",
    "                probability_distribution = {}\n",
    "                for detector_observable, detector_observable_probability in error_probability_distribution.items():\n",
    "                    # no flip\n",
    "                    no_fliped_detector_observable = detector_observable\n",
    "                    no_fliped_probability = detector_observable_probability * (1-flip_probability)\n",
    "                    # flip\n",
    "                    fliped_detector_observable = self.flip_detector_observable_index_by_flip_index(detector_observable, flip_detector_observable_index)\n",
    "                    fliped_probability = detector_observable_probability * flip_probability\n",
    "                    \n",
    "                    # 在同一个错误事件中，可能出现相同的检测器、逻辑观测值，则概率相加\n",
    "                    probability_distribution[no_fliped_detector_observable] = probability_distribution.get(no_fliped_detector_observable, 0) + no_fliped_probability\n",
    "                    probability_distribution[fliped_detector_observable] = probability_distribution.get(fliped_detector_observable, 0) + fliped_probability\n",
    "                # 更新错误概率分布\n",
    "                error_probability_distribution = probability_distribution\n",
    "            # 根据检测器i的值，缩小错误概率分布的范围\n",
    "            error_probability_distribution = {k:v for k,v in error_probability_distribution.items() if syndrome_detector_i == k[detector_i]}\n",
    "        \n",
    "        return error_probability_distribution\n",
    "    \n",
    "    def compute_correcation_error_logical_probability(self, error_syndromes: np.array) -> float:\n",
    "        \"\"\"计算当前这些syndrome解码出错, 可能导致逻辑错误增加的概率。\n",
    "           目前暂时只支持单个逻辑比特的判断。\n",
    "\n",
    "        Args:\n",
    "            error_syndromes (np.array): 出错的syndrome\n",
    "\n",
    "        Returns:\n",
    "            float: 总概率。即所有syndrome解码出错, 可能导致逻辑错误概率。\n",
    "        \"\"\"\n",
    "        error_probability = 0\n",
    "        \n",
    "        for syndrome in error_syndromes:\n",
    "            syndrome_probability_distribution = self.compute_syndrome_probability_distribution(syndrome)\n",
    "            print(f\"error syndrome_probability_distribution:{syndrome_probability_distribution}\")\n",
    "            max_probability_detector_observable =  max(syndrome_probability_distribution, key=syndrome_probability_distribution.get)\n",
    "            probability = 2 * syndrome_probability_distribution[max_probability_detector_observable] - sum(syndrome_probability_distribution.values())\n",
    "            error_probability += probability\n",
    "        \n",
    "        return error_probability\n",
    "    \n",
    "    def compute_correcation_logical_probability(self, error_syndromes: np.array) -> float:\n",
    "        \"\"\"计算当前这些syndrome解码都对了,对应的逻辑错误率是多少？\n",
    "           目前暂时只支持单个逻辑比特的判断。\n",
    "\n",
    "        Args:\n",
    "            error_syndromes (np.array): 出错的syndrome\n",
    "\n",
    "        Returns:\n",
    "            float: 总概率。即所有syndrome解码出错, 可能导致逻辑错误概率。\n",
    "        \"\"\"\n",
    "        logical_error_probability = 0\n",
    "        \n",
    "        for syndrome in error_syndromes:\n",
    "            syndrome_probability_distribution = self.compute_syndrome_probability_distribution(syndrome)\n",
    "            max_probability_detector_observable =  max(syndrome_probability_distribution, key=syndrome_probability_distribution.get)\n",
    "            probability = sum(syndrome_probability_distribution.values()) - syndrome_probability_distribution[max_probability_detector_observable]\n",
    "            logical_error_probability += probability\n",
    "        \n",
    "        return logical_error_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行不同的MLD解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_circuits = [read_circuit(d,r) for d in distances for r in rounds]\n",
    "detector_error_models = [c.detector_error_model() for c in noisy_circuits]\n",
    "decomposed_detector_error_models = [c.detector_error_model(decompose_errors=True) for c in noisy_circuits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 3, round: 1\n",
      "detector number: 8\n",
      "mld_logical_probability: 0.016715913358068574\n",
      "MLD decoding: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], type: <class 'list'>\n",
      "Matching decoding: [array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([1], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8), array([0], dtype=uint8)], type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pymatching\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def tuple_syndromes_2_str_syndromes(tuples_list):\n",
    "    string_list = [''.join(map(str, tpl)) for tpl in tuples_list]\n",
    "    return string_list\n",
    "\n",
    "def array_syndromes_2_str_syndromes(tuples_array):\n",
    "    # 将数组转换为字符串数组\n",
    "    return np.array([''.join(map(str, tpl)) for tpl in tuples_array])\n",
    "    # return np.char.join('', tuples_array.astype(str))\n",
    "\n",
    "def experiment_ml_match_decoder(d: int, r: int, max_syndrome_number: Union[int, None] = None)-> Tuple[List[int], np.array]:\n",
    "    # 控制问题的规模\n",
    "    ## 读取circuit\n",
    "    print(f\"distance: {d}, round: {r}\")\n",
    "    noisy_circuit = read_circuit(d,r)\n",
    "    detector_error_model = noisy_circuit.detector_error_model()\n",
    "    detector_number = detector_error_model.num_detectors\n",
    "    decomposed_detector_error_model = noisy_circuit.detector_error_model(decompose_errors = True)\n",
    "    print(f\"detector number: {detector_number}\")\n",
    "    # print(f\"detector error model: {detector_error_model}\")\n",
    "    # print(f\"decomposed detector error model: {decomposed_detector_error_model}\")\n",
    "    \n",
    "    # ml和matching解码器\n",
    "    ml_decoder = MaxLikelihoodDecoder(detector_error_model = detector_error_model)\n",
    "    match_decoder = pymatching.Matching.from_detector_error_model(decomposed_detector_error_model)\n",
    "    \n",
    "    possible_syndromes_array: np.ndarray\n",
    "    possible_syndromes_str: List[str]\n",
    "    \n",
    "    ## 生成可能的syndrome输入\n",
    "    if max_syndrome_number is None:\n",
    "        possible_syndromes_array = np.indices((2,) * detector_number).reshape(detector_number, -1).T\n",
    "        possible_syndromes_str = array_syndromes_2_str_syndromes(possible_syndromes_array)\n",
    "    else:\n",
    "        possible_syndromes_array = np.indices((2,) * detector_number).reshape(detector_number, -1).T[:max_syndrome_number]\n",
    "        possible_syndromes_str = array_syndromes_2_str_syndromes(possible_syndromes_array)\n",
    "    # print(possible_syndromes_array, possible_syndromes_str)\n",
    "    ## 进行MLD解码\n",
    "    ml_correcation = ml_decoder.decode(possible_syndromes_str)\n",
    "    ## 进行Matching解码\n",
    "    match_correcation = match_decoder.decode_batch(possible_syndromes_array == 0)\n",
    "    \n",
    "    #基于mld解码得到的逻辑错误率应该为：\n",
    "    mld_logical_probability = ml_decoder.compute_correcation_logical_probability(possible_syndromes_str)\n",
    "    print(f\"mld_logical_probability: {mld_logical_probability}\")\n",
    "    print(f\"MLD decoding: {ml_correcation}, type: {type(ml_correcation)}\")\n",
    "    print(f\"Matching decoding: {list(match_correcation)}, type: {type(match_correcation)}\")\n",
    "    return ml_correcation, match_correcation\n",
    "\n",
    "ml_correcation, match_correcation = experiment_ml_match_decoder(d=3, r=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syndrome: 2, ML: 0, Matching: [1]\n",
      "syndrome: 7, ML: 0, Matching: [1]\n",
      "syndrome: 8, ML: 0, Matching: [1]\n",
      "syndrome: 13, ML: 0, Matching: [1]\n",
      "syndrome: 19, ML: 0, Matching: [1]\n",
      "syndrome: 21, ML: 0, Matching: [1]\n",
      "syndrome: 22, ML: 0, Matching: [1]\n",
      "syndrome: 25, ML: 0, Matching: [1]\n",
      "syndrome: 28, ML: 0, Matching: [1]\n",
      "syndrome: 31, ML: 0, Matching: [1]\n",
      "syndrome: 42, ML: 0, Matching: [1]\n",
      "syndrome: 47, ML: 0, Matching: [1]\n",
      "syndrome: 52, ML: 0, Matching: [1]\n",
      "syndrome: 53, ML: 0, Matching: [1]\n",
      "syndrome: 55, ML: 0, Matching: [1]\n",
      "syndrome: 59, ML: 0, Matching: [1]\n",
      "syndrome: 60, ML: 0, Matching: [1]\n",
      "syndrome: 61, ML: 0, Matching: [1]\n",
      "syndrome: 62, ML: 0, Matching: [1]\n",
      "syndrome: 64, ML: 0, Matching: [1]\n",
      "syndrome: 67, ML: 0, Matching: [1]\n",
      "syndrome: 70, ML: 0, Matching: [1]\n",
      "syndrome: 73, ML: 0, Matching: [1]\n",
      "syndrome: 74, ML: 0, Matching: [1]\n",
      "syndrome: 76, ML: 0, Matching: [1]\n",
      "syndrome: 81, ML: 0, Matching: [1]\n",
      "syndrome: 82, ML: 0, Matching: [1]\n",
      "syndrome: 87, ML: 0, Matching: [1]\n",
      "syndrome: 88, ML: 0, Matching: [1]\n",
      "syndrome: 91, ML: 0, Matching: [1]\n",
      "syndrome: 93, ML: 0, Matching: [1]\n",
      "syndrome: 98, ML: 0, Matching: [1]\n",
      "syndrome: 107, ML: 0, Matching: [1]\n",
      "syndrome: 110, ML: 0, Matching: [1]\n",
      "syndrome: 115, ML: 0, Matching: [1]\n",
      "syndrome: 122, ML: 0, Matching: [1]\n",
      "syndrome: 127, ML: 0, Matching: [1]\n",
      "syndrome: 128, ML: 0, Matching: [1]\n",
      "syndrome: 129, ML: 0, Matching: [1]\n",
      "syndrome: 133, ML: 0, Matching: [1]\n",
      "syndrome: 145, ML: 0, Matching: [1]\n",
      "syndrome: 148, ML: 0, Matching: [1]\n",
      "syndrome: 151, ML: 0, Matching: [1]\n",
      "syndrome: 157, ML: 0, Matching: [1]\n",
      "syndrome: 158, ML: 0, Matching: [1]\n",
      "syndrome: 159, ML: 0, Matching: [1]\n",
      "syndrome: 162, ML: 0, Matching: [1]\n",
      "syndrome: 163, ML: 0, Matching: [1]\n",
      "syndrome: 167, ML: 0, Matching: [1]\n",
      "syndrome: 179, ML: 0, Matching: [1]\n",
      "syndrome: 181, ML: 0, Matching: [1]\n",
      "syndrome: 182, ML: 0, Matching: [1]\n",
      "syndrome: 189, ML: 0, Matching: [1]\n",
      "syndrome: 191, ML: 0, Matching: [1]\n",
      "syndrome: 193, ML: 0, Matching: [1]\n",
      "syndrome: 194, ML: 0, Matching: [1]\n",
      "syndrome: 196, ML: 0, Matching: [1]\n",
      "syndrome: 197, ML: 0, Matching: [1]\n",
      "syndrome: 200, ML: 0, Matching: [1]\n",
      "syndrome: 202, ML: 0, Matching: [1]\n",
      "syndrome: 208, ML: 0, Matching: [1]\n",
      "syndrome: 211, ML: 0, Matching: [1]\n",
      "syndrome: 213, ML: 0, Matching: [1]\n",
      "syndrome: 217, ML: 0, Matching: [1]\n",
      "syndrome: 219, ML: 0, Matching: [1]\n",
      "syndrome: 224, ML: 0, Matching: [1]\n",
      "syndrome: 227, ML: 0, Matching: [1]\n",
      "syndrome: 230, ML: 0, Matching: [1]\n",
      "syndrome: 231, ML: 0, Matching: [1]\n",
      "syndrome: 232, ML: 0, Matching: [1]\n",
      "syndrome: 234, ML: 0, Matching: [1]\n",
      "syndrome: 241, ML: 0, Matching: [1]\n",
      "syndrome: 242, ML: 0, Matching: [1]\n",
      "syndrome: 247, ML: 0, Matching: [1]\n",
      "syndrome: 249, ML: 0, Matching: [1]\n",
      "syndrome: 251, ML: 0, Matching: [1]\n",
      "error number: 76\n"
     ]
    }
   ],
   "source": [
    "error_number = 0\n",
    "error_syndrome_index = []\n",
    "\n",
    "for i in range(len(ml_correcation)):\n",
    "    if ml_correcation[i] != match_correcation[i]:\n",
    "        error_number += 1\n",
    "        error_syndrome_index.append(i)\n",
    "        print(f\"syndrome: {i}, ML: {ml_correcation[i]}, Matching: {match_correcation[i]}\")\n",
    "print(f\"error number: {error_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在d=3，r=1的情况下，存在76个解码不是最大似然的解码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error syndrome_probability_distribution:{'000000100': 0.0073629635938100855, '000000101': 0.0006354273805250249}\n",
      "error syndrome_probability_distribution:{'000001111': 2.866803847168359e-05, '000001110': 0.00017297864980007902}\n",
      "error syndrome_probability_distribution:{'000010001': 0.04422880892407683, '000010000': 0.0008033446947689669}\n",
      "error syndrome_probability_distribution:{'000011010': 7.95983505363389e-05, '000011011': 0.0012538825218527654}\n",
      "error syndrome_probability_distribution:{'000100110': 0.00028584278840838986, '000100111': 2.461247207632911e-05}\n",
      "error syndrome_probability_distribution:{'000101011': 0.0005132327675028404, '000101010': 0.00044394188539517406}\n",
      "error syndrome_probability_distribution:{'000101101': 5.963460476636275e-06, '000101100': 3.2000576479563215e-05}\n",
      "error syndrome_probability_distribution:{'000110011': 0.00169223405116469, '000110010': 0.00023187966545485034}\n",
      "error syndrome_probability_distribution:{'000111000': 2.8208092153693237e-05, '000111001': 0.00019980405114062915}\n",
      "error syndrome_probability_distribution:{'000111110': 7.317709820891087e-06, '000111111': 7.747449501376261e-06}\n",
      "error syndrome_probability_distribution:{'001010101': 0.0011559060964612307, '001010100': 0.00015236568227740125}\n",
      "error syndrome_probability_distribution:{'001011110': 5.234143568567598e-06, '001011111': 3.382297547017197e-05}\n",
      "error syndrome_probability_distribution:{'001101001': 7.157726484011472e-06, '001101000': 3.117344970133828e-05}\n",
      "error syndrome_probability_distribution:{'001101011': 6.72796350437807e-06, '001101010': 2.0117926999152066e-05}\n",
      "error syndrome_probability_distribution:{'001101111': 1.34317943383484e-05, '001101110': 1.1771230224435188e-05}\n",
      "error syndrome_probability_distribution:{'001110111': 4.428041834007452e-05, '001110110': 1.1899420886347857e-05}\n",
      "error syndrome_probability_distribution:{'001111000': 1.6582040518132118e-05, '001111001': 3.7289315217014257e-06}\n",
      "error syndrome_probability_distribution:{'001111010': 3.5114560530189218e-06, '001111011': 4.310165002665835e-06}\n",
      "error syndrome_probability_distribution:{'001111100': 1.330435379318523e-06, '001111101': 5.316631664027769e-06}\n",
      "error syndrome_probability_distribution:{'010000001': 0.0022428642525842723, '010000000': 8.350399339486603e-05}\n",
      "error syndrome_probability_distribution:{'010000111': 2.890029217742672e-06, '010000110': 6.631529332445723e-06}\n",
      "error syndrome_probability_distribution:{'010001100': 0.00022787682609636052, '010001101': 1.9730005767792598e-05}\n",
      "error syndrome_probability_distribution:{'010010010': 1.0865344228812687e-05, '010010011': 7.608618880201987e-05}\n",
      "error syndrome_probability_distribution:{'010010100': 3.030470437009739e-06, '010010101': 3.214768525445144e-05}\n",
      "error syndrome_probability_distribution:{'010011001': 0.0013698342095330902, '010011000': 2.5143033395635635e-05}\n",
      "error syndrome_probability_distribution:{'010100011': 9.040294576227324e-05, '010100010': 0.00017344272929642552}\n",
      "error syndrome_probability_distribution:{'010100101': 3.181555927295522e-06, '010100100': 3.060040406211093e-05}\n",
      "error syndrome_probability_distribution:{'010101110': 9.537504764300772e-06, '010101111': 8.929939777831398e-07}\n",
      "error syndrome_probability_distribution:{'010110000': 6.595761165185842e-06, '010110001': 0.0001852136432204048}\n",
      "error syndrome_probability_distribution:{'010110110': 3.054216776428051e-06, '010110111': 1.4545228395835131e-06}\n",
      "error syndrome_probability_distribution:{'010111011': 5.751766947974253e-05, '010111010': 7.5735166293624315e-06}\n",
      "error syndrome_probability_distribution:{'011000101': 5.855047076768435e-05, '011000100': 2.2566113582431633e-06}\n",
      "error syndrome_probability_distribution:{'011010110': 4.119013069836148e-07, '011010111': 2.166006709748441e-06}\n",
      "error syndrome_probability_distribution:{'011011101': 3.580508580622212e-05, '011011100': 4.72315219071041e-06}\n",
      "error syndrome_probability_distribution:{'011100111': 2.3772549346106585e-06, '011100110': 4.6805074118224455e-06}\n",
      "error syndrome_probability_distribution:{'011110100': 7.186864212863711e-07, '011110101': 4.856278405448774e-06}\n",
      "error syndrome_probability_distribution:{'011111111': 1.5099165713227744e-06, '011111110': 3.9124720335244075e-07}\n",
      "error syndrome_probability_distribution:{'100000001': 0.011222407283050781, '100000000': 0.0005148837126840296}\n",
      "error syndrome_probability_distribution:{'100000011': 0.0006801090977581249, '100000010': 0.006672400494433695}\n",
      "error syndrome_probability_distribution:{'100001010': 0.00019965832233667882, '100001011': 0.00039835021738607475}\n",
      "error syndrome_probability_distribution:{'100100011': 0.00043303943531554736, '100100010': 0.00027257652463902473}\n",
      "error syndrome_probability_distribution:{'100101000': 7.045438439659354e-05, '100101001': 9.874444635721982e-05}\n",
      "error syndrome_probability_distribution:{'100101110': 2.58623876066922e-06, '100101111': 7.491969021375304e-07}\n",
      "error syndrome_probability_distribution:{'100111011': 3.204425412762429e-05, '100111010': 1.7099522009126934e-05}\n",
      "error syndrome_probability_distribution:{'100111101': 1.6228325301536772e-06, '100111100': 2.1940219687610482e-06}\n",
      "error syndrome_probability_distribution:{'100111111': 5.566657959370647e-07, '100111110': 3.056101469219409e-06}\n",
      "error syndrome_probability_distribution:{'101000101': 0.0002991717545944122, '101000100': 9.006123915554075e-05}\n",
      "error syndrome_probability_distribution:{'101000111': 1.8946324663335547e-05, '101000110': 0.000181814373120205}\n",
      "error syndrome_probability_distribution:{'101001110': 7.1792946863829195e-06, '101001111': 1.0713440263818953e-05}\n",
      "error syndrome_probability_distribution:{'101100111': 1.1569300323575698e-05, '101100110': 1.0220535318305595e-05}\n",
      "error syndrome_probability_distribution:{'101101010': 6.838863928891782e-06, '101101011': 5.889265515705207e-06}\n",
      "error syndrome_probability_distribution:{'101101100': 2.181332084080875e-06, '101101101': 2.6397749902012557e-06}\n",
      "error syndrome_probability_distribution:{'101111011': 8.009390556717477e-07, '101111010': 2.5754215004806882e-06}\n",
      "error syndrome_probability_distribution:{'101111111': 9.221813637355226e-07, '101111110': 5.663223159064635e-07}\n",
      "error syndrome_probability_distribution:{'110000010': 9.156824852350507e-06, '110000011': 3.2655864102853234e-05}\n",
      "error syndrome_probability_distribution:{'110000100': 1.6542468795763668e-06, '110000101': 1.8483245378427678e-06}\n",
      "error syndrome_probability_distribution:{'110001001': 0.00035594167860229347, '110001000': 1.6255251241051668e-05}\n",
      "error syndrome_probability_distribution:{'110001011': 2.160769927067648e-05, '110001010': 0.0002079148231687873}\n",
      "error syndrome_probability_distribution:{'110010001': 8.603440652961916e-05, '110010000': 3.211139001213781e-06}\n",
      "error syndrome_probability_distribution:{'110010101': 1.0112813868790154e-06, '110010100': 2.103472762793859e-06}\n",
      "error syndrome_probability_distribution:{'110100000': 4.877842255556002e-06, '110100001': 5.512033769054675e-05}\n",
      "error syndrome_probability_distribution:{'110100110': 5.163508549198119e-07, '110100111': 1.5996167540953995e-07}\n",
      "error syndrome_probability_distribution:{'110101011': 1.5518187726186e-05, '110101010': 9.253729512111592e-06}\n",
      "error syndrome_probability_distribution:{'110110011': 6.03990742795706e-06, '110110010': 6.226193090424576e-06}\n",
      "error syndrome_probability_distribution:{'110110111': 1.267083684689005e-07, '110110110': 5.81944315335284e-07}\n",
      "error syndrome_probability_distribution:{'111000000': 2.313340858303488e-06, '111000001': 2.303647823080812e-05}\n",
      "error syndrome_probability_distribution:{'111000110': 3.155725885900322e-07, '111000111': 8.845487522993457e-07}\n",
      "error syndrome_probability_distribution:{'111001101': 9.484705318793238e-06, '111001100': 2.7958506869784724e-06}\n",
      "error syndrome_probability_distribution:{'111001111': 6.066536228228296e-07, '111001110': 5.664399342035747e-06}\n",
      "error syndrome_probability_distribution:{'111010001': 9.85190804429948e-07, '111010000': 2.5283216942483083e-06}\n",
      "error syndrome_probability_distribution:{'111010101': 2.5656079040642957e-06, '111010100': 1.4242550386764293e-07}\n",
      "error syndrome_probability_distribution:{'111100010': 2.1273020629764384e-06, '111100011': 1.2325285696618604e-06}\n",
      "error syndrome_probability_distribution:{'111100100': 4.4618088233799374e-07, '111100101': 1.470402393914263e-06}\n",
      "error syndrome_probability_distribution:{'111101111': 4.1473771370788326e-07, '111101110': 3.455356039669598e-07}\n",
      "error syndrome_probability_distribution:{'111110011': 2.1447243823317514e-07, '111110010': 1.2080207755335511e-06}\n",
      "error syndrome_probability_distribution:{'111110111': 1.762337944716394e-07, '111110110': 2.0433642589403795e-07}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0770566141892485"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_syndromes = np.indices((2,) * 8).reshape(8, -1).T[error_syndrome_index]\n",
    "ml_decoder = MaxLikelihoodDecoder(detector_error_model = detector_error_models[0])\n",
    "error_syndromes_str = array_syndromes_2_str_syndromes(error_syndromes)\n",
    "ml_decoder.compute_correcation_error_logical_probability(error_syndromes_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "ml_decoder = MaxLikelihoodDecoder(detector_error_model = detector_error_models[0])\n",
    "print(ml_decoder.decode([\"00000010\"]))\n",
    "\n",
    "matching_decoder = pymatching.Matching.from_detector_error_model(decomposed_detector_error_models[0])\n",
    "print(matching_decoder.decode(np.array([0, 0, 0, 0, 0, 0, 1, 0])== 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "ml_decoder = MaxLikelihoodDecoder(detector_error_model = detector_error_models[0])\n",
    "print(ml_decoder.decode([\"00000111\"]))\n",
    "\n",
    "matching_decoder = pymatching.Matching.from_detector_error_model(decomposed_detector_error_models[0])\n",
    "print(matching_decoder.decode(np.array([0, 0, 0, 0, 0, 1, 1, 1])== 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果全部解码正确，理论上会比一次逻辑错误率会降低0.07770195797224559。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样的话，就说明了一些分解操作，引起的错误率会降低是蛮大的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果想要全部syndrome都输入，找到不同，syndrome的规模太大。\n",
    "\n",
    "detector的数量为：\n",
    "$$d^2*r-r$$\n",
    "\n",
    "你们对应的syndrome的可能数为：\n",
    "$$2^{d^2*r-r}$$\n",
    "\n",
    "所以，如果d=3，r=1，那么syndrome的可能数为：\n",
    "$$2^{3^2*1-1} = 2^{8} = 256$$\n",
    "\n",
    "如果d=3，r=3，那么syndrome的可能数为：\n",
    "$$2^{3^2*3-3} = 2^{24} = 1.6777216 * 10^{7}$$\n",
    "\n",
    "如果d=3，r=5，那么syndrome的可能数为：\n",
    "$$2^{3^2*5-5} = 2^{40} = 1.099511627776 * 10^{12}$$\n",
    "\n",
    "如果d=3，r=7，那么syndrome的可能数为：\n",
    "$$2^{3^2*7-7} = 2^{56} = 7.2057594037927936 * 10^{16}$$\n",
    "\n",
    "如果d=5, r=1，那么syndrome的可能数为：\n",
    "$$2^{5^2*1-1} = 2^{24} = 1.6777216 * 10^{7}$$\n",
    "\n",
    "如果d=5, r=3，那么syndrome的可能数为：\n",
    "$$2^{5^2*3-3} = 2^{72} = 4.722366482869647 * 10^{21}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_qec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
